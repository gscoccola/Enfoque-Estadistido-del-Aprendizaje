---
title: "TP"
output: html_document
date: "2022-09-28"
---

```{r setup, include=FALSE}
rm( list=ls() )  #remove all objects
knitr::opts_chunk$set(echo = TRUE)
```

## Leer el archivo "encuesta_salud_train.csv". ¿Qué puede mencionar sobre su estructura y variables?

Defino las librerias que voy a usar.

```{r}
require("data.table")
library(tidyverse)
library(tidymodels)
library(modelr)
library(corrplot)
library(moderndive)
library(lattice)
library(reshape2)
library(ggpubr)
library(forcats)
library(Metrics)
library(stringi)
require(foreign)
require(MASS)
theme_set(theme_pubr())
```

Leo los datos de la encuesta mundial de la salud escolar.

```{r}
#Establezco la carpeta de trabajo
setwd("C:\\Users\\PC\\Documents\\eea2022_tp1_scoccola_gabriel")  

#Cargo el dataset
DT  <- fread("./encuesta_salud_train.csv")
DT_test  <- fread("./encuesta_salud_test.csv")
DT_6  <- fread("./encuesta_salud_modelo6.csv")

#Veo los nombres y tipos de datos de las columnas
sapply(DT, class)
```

Los datos conforman una matriz de 16 columnas y 7024 filas.

La primera columna es una ID de cada alumno entrevistado. Luego hay 6 variables numéricas (edad, altura, peso, dias_consumo_comida_rapida, consumo_diario_alcohol, dias_actividad_fisica_semanal) una variables categórica (genero) y 8 variables ordinales (nivel_educativo, frecuencia_hambre_mensual, edad_consumo_alcohol, consumo_semanal_frutas, consumo_semanal_verdura, consumo_semanal_gaseosas, consumo_semanal_snacks y consumo_semanal_comida_grasa).

Para facilitar la lectura de código, gráficos y tablas, abrevio los nombres de las columnas.

```{r}
colnames(DT) <- c('ID','edad', 'genero', 'n_educ', 'altura', 'peso', 'f_hambre', 'c_rapida', 'e_alcohol', 'c_alcohol', 'a_fisica', 'c_frutas', 'c_verdura', 'c_gaseosa', 'c_snacks', 'c_grasa')

colnames(DT_test) <- c('ID','edad', 'genero', 'n_educ', 'altura', 'peso', 'f_hambre', 'c_rapida', 'e_alcohol', 'c_alcohol', 'a_fisica', 'c_frutas', 'c_verdura', 'c_gaseosa', 'c_snacks', 'c_grasa')

colnames(DT_6) <- c('ID','edad', 'genero', 'n_educ', 'altura', 'peso', 'f_hambre', 'c_rapida', 'e_alcohol', 'c_alcohol', 'a_fisica', 'c_frutas', 'c_verdura', 'c_gaseosa', 'c_snacks', 'c_grasa')

```

Además, le saco las tildes a los datos para que no generen problemas más adelante.

```{r}
#Saco las tildes a las columnas que voy a analizar
DT$c_snacks <- stri_trans_general(str = DT$c_snacks, id = "Latin-ASCII")
DT$f_hambre <- stri_trans_general(str = DT$f_hambre, id = "Latin-ASCII")
DT$c_grasa <- stri_trans_general(str = DT$c_grasa, id = "Latin-ASCII")
DT$c_frutas <- stri_trans_general(str = DT$c_frutas, id = "Latin-ASCII")
DT$c_verdura <- stri_trans_general(str = DT$c_verdura, id = "Latin-ASCII")
DT$c_gaseosa <- stri_trans_general(str = DT$c_gaseosa, id = "Latin-ASCII")
DT$e_alcohol <- stri_trans_general(str = DT$e_alcohol, id = "Latin-ASCII")

DT_test$c_snacks <- stri_trans_general(str = DT_test$c_snacks, id = "Latin-ASCII")
DT_test$f_hambre <- stri_trans_general(str = DT_test$f_hambre, id = "Latin-ASCII")
DT_test$c_grasa <- stri_trans_general(str = DT_test$c_grasa, id = "Latin-ASCII")
DT_test$c_frutas <- stri_trans_general(str = DT_test$c_frutas, id = "Latin-ASCII")
DT_test$c_verdura <- stri_trans_general(str = DT_test$c_verdura, id = "Latin-ASCII")
DT_test$c_gaseosa <- stri_trans_general(str = DT_test$c_gaseosa, id = "Latin-ASCII")
DT_test$e_alcohol <- stri_trans_general(str = DT_test$e_alcohol, id = "Latin-ASCII")

```

## ¿Cómo es la correlación entre las variables numéricas? Utilice y analice en detalle algún gráfico que sirva para sacar conclusiones sobre la asociación de variables realizando apertura por género. En particular, ¿cómo es la correlación entre la variable a explicar (peso) y el resto de las variables numéricas?

Divido los registros según el género, y calculo las matrices de correlación entre las variables númericas.

```{r}
#Separo el dataset por género
DT_fem=DT[genero=="Femenino"]
DT_mas=DT[genero=="Masculino"]

#Calculo las matrices de correlación para cada género
cor_fem=cor(DT_fem[, c("edad", "altura", "peso", "c_rapida",
                       "c_alcohol", "a_fisica"), with=FALSE])

cor_mas=cor(DT_mas[, c("edad", "altura", "peso", "c_rapida",
                       "c_alcohol", "a_fisica"), with=FALSE])

cor_fem
cor_mas
```

Realizo un gráfico de las correlaciones como heatmaps.

```{r, fig.dim = c(12, 7)}
#Reformateo las matrices de correlación
melted_cormat1 <- melt(cor_fem)
melted_cormat2 <- melt(cor_mas)

#Genero los gráficos para cada valor de genero
p1 <- ggplot(data = melted_cormat1, aes(x=Var1, y=Var2, fill=value)) +  geom_tile()+  scale_x_discrete(guide = guide_axis(angle = 90)) + xlab("")+ ylab("")


p2 <- ggplot(data = melted_cormat2, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() + scale_x_discrete(guide = guide_axis(angle = 90))+ xlab("")+ ylab("")

#Junto los gráficos para que aparezcan lado a lado
figure <- ggarrange(p1, p2,
                    labels = c("Femenino", "Masculino"),
                    ncol = 2, nrow = 1,  common.legend = TRUE, legend = "bottom")
figure
```

\
Las correlaciones caen en el intervalo [-0.09, 1], por lo que no hay correlaciones negativas de valores altos. En cambio sí hay varias correlaciones positivas de valores altos, en particular entre las variables edad, altura y peso.

Si quiero ver en particular las correlaciones que incluyen el peso:

```{r}
cor_fem[3,]

cor_mas[3,]
```

La altura es la variable con mayor correlación con el peso para ambos sexos, seguida de la edad. Estas dos correlaciones son aún más grandes para el género masculino.

El consumo de comida rapida se correlaciona negativamente, en mayor medida para el género masculino.

El consumo de alcohol se correlaciona positivamente con el peso, en mayor medida para el género masculino.

Los actividad física semanal se correlaciona positivamente con el peso, y es la única correlación más acentuada en el género femenino.

## Para las categorías de la variable frecuencia de hambre mensual, analice gráficamente la distribución en términos de frecuencia relativa de:

## a) El consumo semanal de verdura.

## b) El consumo semanal de comida grasa.

## ¿Cuáles son las principales características que observa en estos gráficos?

Genero el gráfico del consumo semanal de verdura para distintos niveles de frecuencia de hambre mensual.

```{r, fig.dim = c(12, 7)}

DT$f_hambre <- factor(DT$f_hambre, c("Nunca", "Rara vez", "Algunas veces", "Casi siempre", "Siempre"))

#Corto los datos según el valor de f_hambre
h0=DT[f_hambre=="Nunca"]
h1=DT[f_hambre=="Rara vez"]
h2=DT[f_hambre=="Algunas veces"]
h3=DT[f_hambre=="Casi siempre"]
h4=DT[f_hambre=="Siempre"]



#Explicito el orden de los valores de c_verdura
positions <- c("4 o mA!s veces al dA-a", "3 veces al dA-a", "2 veces al dA-a", "1 vez al dA-a", "4 a 6 veces durante los Aºltimos 7 dA-as", "1 a 3 veces durante los Aºltimos 7 dA-as", "No comA- verduras ni hortalizas durante los Aºltimos 7 dA-as", "Dato perdido")

#Arreglo los acentos en los niveles
niveles <- c("4 o más veces al día", "3 veces al día", "2 veces al día", "1 vez al día", "4 a 6 veces durante los últimos 7 día", "1 a 3 veces durante los últimos 7 día", "No comí verduras ni hortalizas durante los últimos 7 día", "Dato perdido")



h0$c_verdura <- factor(h0$c_verdura, levels = positions)
h1$c_verdura <- factor(h1$c_verdura, levels = positions)
h2$c_verdura <- factor(h2$c_verdura, levels = positions)
h3$c_verdura <- factor(h3$c_verdura, levels = positions)
h4$c_verdura <- factor(h4$c_verdura, levels = positions)


#Genero los gráficos para cada nivel de f_hambre
p5=ggplot(h0, aes(x=h0$c_verdura, fill=h0$c_verdura)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h0)[1]/2.5) + scale_fill_discrete(labels=niveles)


p6=ggplot(h1, aes(x=h1$c_verdura, fill=h1$c_verdura)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h1)[1]/2.5) + scale_fill_discrete(labels=niveles) 


p7=ggplot(h2, aes(x=h2$c_verdura, fill=h2$c_verdura)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h2)[1]/2.5)+ scale_fill_discrete(labels=niveles)

p8=ggplot(h3, aes(x=h3$c_verdura, fill=h3$c_verdura)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h3)[1]/2.5)+ scale_fill_discrete(labels=niveles)

p9=ggplot(h4, aes(x=h4$c_verdura, fill=h4$c_verdura)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h4)[1]/2.5)+ scale_fill_discrete(labels=niveles)

#Junto los gráficos
figure <- ggarrange(p5, p6, p7, p8, p9,
                    labels = c("Nunca", "Rara vez", "Algunas veces", "Casi siempre", "Siempre"),
                    ncol = 5, nrow = 1,
                    common.legend = TRUE, legend = "bottom")
figure

#Observaciones por nivel de f_hambre
as.data.frame(table(DT$f_hambre))
```

Se observa que la cantidad de datos va disminuyendo para mayor frecuencia de hambre. En particular "casi siempre" y "siempre tienen menos de 100 casos cada una, por lo que sus distribuciones son poco representativas.

Lo que se observa consistentemente en los primeros 3 nivéles de f_hambre, es que a medida que crece la frecuencia de hambre, disminuyen relativamente las ocurrencias de "4 o más veces al día", y aumentan relativamente las de "1 a 3 veces durante los últimos 7 día" y de "No comí verduras ni hortalizas durante los últimos 7 día".

```{r, fig.dim = c(12, 7)}

#Corto los datos según el valor de f_hambre
h0=DT[f_hambre=="Nunca"]
h1=DT[f_hambre=="Rara vez"]
h2=DT[f_hambre=="Algunas veces"]
h3=DT[f_hambre=="Casi siempre"]
h4=DT[f_hambre=="Siempre"]

#Explicito el orden de los valores de c_grasa
positions <- c("4 o mA!s veces al dA-a", "3 veces al dA-a", "2 veces al dA-a", "1 vez al dA-a", "4 a 6 veces durante los Aºltimos 7 dA-as", "1 a 3 veces durante los Aºltimos 7 dA-as", "No comA- comida alta en grasa en los Aºltimos 7 dA-as", "Dato perdido")

#Arreglo los acentos en los niveles
niveles <- c("4 o más veces al día", "3 veces al día", "2 veces al día", "1 vez al día", "4 a 6 veces durante los últimos 7 día", "1 a 3 veces durante los últimos 7 día", "No comí comida alta en grasa en los los últimos 7 día", "Dato perdido")

h0$c_grasa <- factor(h0$c_grasa, levels = positions)
h1$c_grasa <- factor(h1$c_grasa, levels = positions)
h2$c_grasa <- factor(h2$c_grasa, levels = positions)
h3$c_grasa <- factor(h3$c_grasa, levels = positions)
h4$c_grasa <- factor(h4$c_grasa, levels = positions)

#Genero los gráficos para cada nivel de f_hambre
p0=ggplot(h0, aes(x=h0$c_grasa, fill=h0$c_grasa)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h0)[1]/2) + scale_fill_discrete(labels=niveles)

p1=ggplot(h1, aes(x=h1$c_grasa, fill=h1$c_grasa)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h1)[1]/2)+ scale_fill_discrete(labels=niveles)

p2=ggplot(h2, aes(x=h2$c_grasa, fill=h2$c_grasa)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h2)[1]/2)+ scale_fill_discrete(labels=niveles)

p3=ggplot(h3, aes(x=h3$c_grasa, fill=h3$c_grasa)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h3)[1]/2)+ scale_fill_discrete(labels=niveles)

p4=ggplot(h4, aes(x=h4$c_grasa, fill=h4$c_grasa)) +
  geom_bar(position="dodge")+ scale_x_discrete(labels = c('','','','','','','',''), limits = positions)+ xlab("") + ylab("") + ylim(0,dim(h4)[1]/2)+ scale_fill_discrete(labels=niveles)

#Junto los gráficos
figure <- ggarrange(p0, p1, p2, p3, p4,
                    labels = c("Nunca", "Rara vez", "Algunas veces", "Casi siempre", "Siempre"),
                    ncol = 5, nrow = 1,
                    common.legend = TRUE, legend = "bottom")
figure

as.data.frame(table(h0$c_grasa))

```

Se observa en los primeros 3 nivéles de f_hambre que a medida que crece la frecuencia de hambre, aumentan la proporción de datos que corresponden a comida alta en grasa 1 vez, 2 veces, 3 veces y 4 o más veces al día. Y disminuyen en cambio las proporciones de "1 a 3 veces durante los últimos 7 día" y "No comí comida alta en grasa en los los últimos 7 día".

### 2) Modelo inicial

### Se plantea que una primera alternativa para modelar el peso es:

### E(peso) = β0 +β1altura+β2edad+β3genero+β4diasActividadF isicaSemanal+β5consumoDiarioAlcohol

### ¿Cuál es la interpretación de cada uno de los coeficientes estimados? ¿Son significativos? ¿El modelo resulta significativo para explicar el peso? ¿Qué porcentaje de la variabilidad explica el modelo?

Realizamos el modelo lineal multiple:

```{r}
#Ajustamos un modelo lineal múltiple
modelo_inicial <- lm(peso ~ altura+edad+genero+a_fisica+c_alcohol, data = DT)
#Resumen del modelo
summary(modelo_inicial)

```

Para introducir la variable categórica de género, el modelo mapea por default masculino a 1 y femenino a 0. Se podría hacer la elección inversa, y lo único que cambiaría sería los valores de beta_0 y beta_3, así como su interpretación.

Con esta elección el coeficiente beta_0 correspondería al peso de una mujer de edad, altura, frecuencia de actividad física y de consumo de alcohol iguales a cero, que no es un caso realista para estas variables.

El coeficiente beta_3 se corresponde a la diferencia de peso predicha entre un hombre y una mujer que tienen la misma edad, altura, a_fisica y c_alcohol.

beta_1, beta_2, beta_4 y beta_5 son las constantes multiplicativas que predicen la variación del peso en función del crecimiento de la edad, altura frecuencia de actividad física y de consumo de alcohol respectivamente, manteniendo las demas variables fijas.

Si se elige como corte un p-valor de 0.05, solo los coeficientes beta_0, beta_1, beta_2 y beta_3 son significativos.

En total, el modelo sí resulta significativo, con un p-valor de orden de magnitud de -16, y explica una variabilidad de 0.3544.

### 3) Modelo categóricas

### Se sugiere probar un modelo que incopore el consumo semanal de snacks y una interacción entre el género y la edad, en lugar de actividad física y consumo de alcohol:

### E(peso) = β0 + β1altura + β2edad + β3genero + β4consumoSemanalSnacks + β5genero · edad

### Además se pide explícitamente que la categoría "No comí comida salada o snacks en los últimos 7 días" de la variable consumoSemanalSnacks se encuentre como nivel/categoría basal.

Primero establezco como nivel basal a "No comí comida salada o snacks...":

```{r}
#Defino a la variable como factor
DT$c_snacks <- as.factor(DT$c_snacks)
DT_test$c_snacks <- as.factor(DT_test$c_snacks)


#Redefino el baseline
DT$c_snacks <- relevel(DT$c_snacks, ref="No comA- comida salada o snacks en los Aºltimos 7 dA-as")

DT_test$c_snacks <- relevel(DT_test$c_snacks, ref="No comA- comida salada o snacks en los Aºltimos 7 dA-as")
```

Y realizamos el modelo lineal, agregando también el producto de genero y edad:

```{r}
#Ajustamos un modelo lineal múltiple
modelo_categorias <- lm(peso ~ altura+edad+genero+c_snacks+edad*genero, data = DT)
# Resumen del modelo
summary(modelo_categorias)

```

### ¿Cuál es la interpretación de los coeficientes estimados para las categorías de consumoSemanalSnacks y genero . edad? ¿Son significativas? ¿Qué porcentaje de la variabilidad explica el modelo?

Los coeficientes asociados a cada nivel de c_snacks se corresponden a la diferencia de peso predicha entre un alumno con dicho consumo de snacks y uno que no consumió snacks en los últimos 7 días (el nivel basal), con iguales valores de las demás variables. Los coeficientes significativos son los correspondientes a dato perdido, 4 o más veces al día, 1 a 3 veces y 6 a 7 veces en los últimos 7 días.

El coeficiente beta_5 corresponde a la diferencia predicha entre hombres y mujeres de la constante multiplicativa que relaciona la variabción de peso en función de la edad, manteniendo las demás variables fijas. Para mujeres, esta constante multiplicativa se aproxima con beta_2, para hombres con beta_2+beta_5. El coeficiente es significativo para nuestra eleccion de umbral de 0.05, con un p-valor de 0.02880.

En total, el modelo explica una variabilidad de 0.3585, mayor a la del modelo anterior. Su R\^2 ajustado también es mayor, por lo que la mayor explicación no se debe únicamente a la mayor cantidad de parámetros, también a su calidad.

### En caso de detectar que existen categorías no significativas de la variable consumoSemanalSnacks evaluar si la variable es significativa en su conjunto y, en caso afirmativo, proponer una redefinición de las mismas que permita obtener una mayor proporción de categorías significativas individualmente. Luego, analizar si existen cambios en la variabilidad explicada por el modelo.

Las categorías correspondientes a 1, 2 y 3 veces al día no son significativas. Para probar si la variable en conjunto es significativa hago un likelihood ratio test.

```{r}

#La hipótesis nula es el modelo sin c_snacks
modelo_0 <- lm(peso ~ altura+edad+genero+edad*genero, data = DT)

#Con likelihood  
L0 <- logLik(modelo_0)

#El modelo con la variable categórica es la hipótesis alternativa


#Con likelihood 
L1 <- logLik(modelo_categorias)

#Calculo el p-valor
1-pchisq(2*(L1-L0),df=1)
```

La variable es, en conjunto, significativa.

Propongo entonces una redefinición de las categorías juntando aquellas 3 que no son significativas en un mismo nivel.

```{r}
#Junto estos 3 niveles
DT$c_snacks <- fct_collapse(DT$c_snacks, "1 a 3 veces al dia" = c("1 vez al dA-a","3 veces al dA-a", "2 veces al dA-a"))
DT_test$c_snacks <- fct_collapse(DT_test$c_snacks, "1 a 3 veces al dia" = c("1 vez al dA-a","3 veces al dA-a", "2 veces al dA-a"))

#Ajustamos un modelo lineal múltiple
modelo_categorias <- lm(peso ~ altura+edad+genero+c_snacks+edad*genero, data = DT)

#Resumen del modelo
summary(modelo_categorias)

```

En este nuevo modelo, todas los niveles de c_snacks son significativos. La variabilidad explicada disminuye por tener menos variables, pero en forma casi despreciable de 0.3585222713 a 0.3584614819. El R\^2 ajustado en cambio aumenta mínimamente.

### Realizar 2 modelos lineales múltiples adicionales y explicar brevemente la lógica detrás de los mismos (se valorará la creación y/o inclusión de variables nuevas).

Modelo propio 1) Observo que en el dataset hay 5 variables ordinales que describen la frecuencia de consumos de ciertos tipos alimentos. Todas ellas tienen 8 niveles que cubren los mismos intervalos de frecuencia, que van desde cero a más de de 4 veces diarias.

Con el fin de examinar si dichas frecuencias tienen una correlación lineal con el peso, transformo dichas variables ordinales en variables numéricas. A cada nivel lo mapeo por valor medio de frecuencia del intervalo, por ejemplo "1 a 3 veces cada 7 dias" se transforma en 1.5/7. La categoría "más de de 4 veces diarias" que la mapeo a 4.5 como primer aproximación.

Agrego además las 3 variables numéricas todavía no probadas, c_rapida, c_alcohol y a_fisica.

```{r}
#Defino una funcion que, a partir de nuestras varaibles categóricas, cree una variable numérica correspondiente
numerizar  <- function( variable )
{
#Por suerte los niveles se llaman igual entre variables, excepto por el nivel de frecuencia cero. Este último no es necesario llamarlo en la función, ya que en casos de que se dé este nivel, dejamos la nueva variable numérica igual a cero
  
DT[, "new" := (1.5/7)*(get(variable) == "1 a 3 veces durante los Aºltimos 7 dA-as") +(5/7)*(get(variable) == "4 a 6 veces durante los Aºltimos 7 dA-as")+1*(get(variable) == "1 vez al dA-a")+2*(get(variable) == "2 veces al dA-a")+3*(get(variable) == "3 veces al dA-a")+4.5*(get(variable) == "4 o mA!s veces al dA-a")] 

return(DT$new)
  
}

#Analogo en el dataset DT_test
numerizar_test  <- function( variable )
{

DT_test[, "new" := (1.5/7)*(get(variable) == "1 a 3 veces durante los Aºltimos 7 dA-as") +(5/7)*(get(variable) == "4 a 6 veces durante los Aºltimos 7 dA-as")+1*(get(variable) == "1 vez al dA-a")+2*(get(variable) == "2 veces al dA-a")+3*(get(variable) == "3 veces al dA-a")+4.5*(get(variable) == "4 o mA!s veces al dA-a")] 

return(DT_test$new)
  
}
```

Ahora utilizo la función:

```{r}
#Creo las 5 nuevas variables numéricas
DT[,"n_frutas"] <- numerizar("c_frutas")
DT[,"n_snacks"] <- numerizar("c_snacks")
DT[,"n_gaseosa"] <- numerizar("c_gaseosa")
DT[,"n_verdura"] <- numerizar("c_verdura")
DT[,"n_grasa"] <- numerizar("c_grasa")
DT[,"n_snacks"] <- numerizar("c_snacks")

DT_test[,"n_frutas"] <- numerizar_test("c_frutas")
DT_test[,"n_snacks"] <- numerizar_test("c_snacks")
DT_test[,"n_gaseosa"] <- numerizar_test("c_gaseosa")
DT_test[,"n_verdura"] <- numerizar_test("c_verdura")
DT_test[,"n_grasa"] <- numerizar_test("c_grasa")
DT_test[,"n_snacks"] <- numerizar_test("c_snacks")

#Ajustamos un modelo lineal múltiple
modelo_propio_1 <- lm(peso ~ altura + genero + edad + n_gaseosa + n_verdura +n_snacks +n_frutas +n_grasa + n_snacks +  c_rapida + c_alcohol + a_fisica, data = DT)

#Resumen del modelo
summary(modelo_propio_1)
```

Observo que la única variable númerica agregada significativa en nuestro modelo lineal es n_gaseosa. Esto no implica que las variables ordinales originales serían no significativas en caso de ser agregradas, se deberían analizar nivel por nivel. Pero sí implica que c_gaseosa tiene potencial explicativo.

Se probó cambiar los valores de frecuencia al cual mapeo el nivel "4 veces o más", de 4.5 a 4, 5, 6 y 7. Se obvervó que el p-valor de n_gaseosa, que es la única variable que tiene buen valor explicativo, disminuye. Preferimos quedarnos entonces con 4,5.

Modelo propio 2) En este modelo trataremos de aplicar lo aprendido en los puntos anteriores.

Viendo las matrices de correlación separada por generos, observamos que las correlaciones peso-altura y peso-edad cambian considerablemente entre hombres y mujeres. Proponemos entonces para comenzar un modelo que tenga en cuenta ambas variables separadas por género.

```{r}


#Ajustamos un modelo lineal múltiple
modelo_l <- lm(peso ~ altura*genero + edad*genero, data = DT)

#Resumen del modelo
summary(modelo_l)

```

Vemos que el parámetro generoMasculino:edad no es significativo, como sí lo era en el punto anterior. Puede estar ocurriendo que la inclusión de altura:generoMasculino ya explique mejor la diferencia en pesos entre los dos géneros. En todo caso removemos genero\*edad del modelo.

Luego agregamos al modelo c_snacks, con la redefinición de sus niveles anterior. Por último redefinimos el nivel basal de c_gasesosa a "no tomé gaseosa..." y la agregamos:

```{r}

#Defino a la variable como factor
DT$c_gaseosa <- as.factor(DT$c_gaseosa)
DT_test$c_gaseosa <- as.factor(DT_test$c_gaseosa)

#Redefino el baseline
DT$c_gaseosa <- relevel(DT$c_gaseosa, ref="No tomA(C) gaseosas en los Aºltimos 7 dA-as")
DT_test$c_gaseosa <- relevel(DT_test$c_gaseosa, ref="No tomA(C) gaseosas en los Aºltimos 7 dA-as")


#Ajustamos un modelo lineal múltiple
modelo_l1 <- lm(peso ~ altura*genero + edad + c_gaseosa + c_snacks, data = DT)

#Resumen del modelo
summary(modelo_l1)

```

Observamos que los 3 niveles más bajos de c_gaseosa no son significativos, por lo que los agrupamos con el nivel basal. Lo mismo hacemos para el nivel "dato perdido".

Peculiarmente el parámetro asociado a "3 veces al día" tiene menor magnitud (en valor absoluto) y p-valor que el asociado a "2 veces al día". Hay que recordar sin embargo que es el nivel menos representado en la muestra, con solo 281 ocurrencias. En todo caso lo agrupamos con el nivel "2 veces al día".

Por último agrupamos el nivel "1 a 3 veces al día" y "4 o más veces al día"al basal ya no es significativo.

```{r}

#Junto los niveles de Gasoesa
DT$c_gaseosa <- fct_collapse(DT$c_gaseosa, "No tomA(C) gaseosas en los Aºltimos 7 dA-as" = c("Dato perdido", "No tomA(C) gaseosas en los Aºltimos 7 dA-as", "1 vez al dA-a","1 a 3 veces durante los Aºltimos 7 dA-as", "4 a 6 veces durante los Aºltimos 7 dA-as"), "2 o 3 veces al dia" = c("2 veces al dA-a","3 veces al dA-a"))

DT_test$c_gaseosa <- fct_collapse(DT_test$c_gaseosa, "No tomA(C) gaseosas en los Aºltimos 7 dA-as" = c("Dato perdido", "No tomA(C) gaseosas en los Aºltimos 7 dA-as", "1 vez al dA-a","1 a 3 veces durante los Aºltimos 7 dA-as", "4 a 6 veces durante los Aºltimos 7 dA-as"), "2 o 3 veces al dia" = c("2 veces al dA-a","3 veces al dA-a"))


#Junto los niveles de snacks
DT$c_snacks <- fct_collapse(DT$c_snacks, "No comA- comida salada o snacks en los Aºltimos 7 dA-as" = c("No comA- comida salada o snacks en los Aºltimos 7 dA-as", "1 a 3 veces al dia"))
DT_test$c_snacks <- fct_collapse(DT_test$c_snacks, "No comA- comida salada o snacks en los Aºltimos 7 dA-as" = c("No comA- comida salada o snacks en los Aºltimos 7 dA-as", "1 a 3 veces al dia"))


#Ajustamos un modelo lineal múltiple
modelo_propio_2 <- lm(peso ~ altura*genero + edad + c_gaseosa + c_snacks, data = DT)



#Resumen del modelo
summary(modelo_propio_2)
```

Sobre los mismos datos de entrenamiento, este modelo tiene el R cuadrado y R cuadrado ajustado más altos hasta ahora, y ningún parámetro no significativo.

### Evaluar la performance del modelo inicial, el modelo categóricas con las categorías redefinidas de la variable consumoSemanalSnacks y los modelos desarrollados en este punto en el dataset de entrenamiento y evaluación (usar dataset "encuesta_salud_test.csv"). La evaluación de performance consiste en comparar la performance en términos del R cuadrado ajustado, RMSE y MAE sobre el set de entrenamiento y en términos de RMSE y MAE sobre el set de evaluación. ¿Cuál es el mejor modelo para nuestro objetivo de predecir el peso? ¿Por qué?

Los R cuadrado ajustados para el set de entrenamiento ya los calculé, son 0.3539, 0.3576, 0.3559 y 0.3594, correspondientes al modelo inicial, categorías, propio 1 y propio 2. Calculo ahora los RMSE y MAE:

```{r}

#obtengo los valores reales
actual_train <- DT$peso
actual_test <- DT_test$peso

#Obtengo los valores predichos
predicted_train_ini <- predict.lm(modelo_inicial, DT)
predicted_train_cat <- predict.lm(modelo_categorias, DT)
predicted_train_pr1 <- predict.lm(modelo_propio_1, DT)
predicted_train_pr2 <- predict.lm(modelo_propio_2, DT)

predicted_test_ini <- predict.lm(modelo_inicial, DT_test)
predicted_test_cat <- predict.lm(modelo_categorias, DT_test)
predicted_test_pr1 <- predict.lm(modelo_propio_1, DT_test)
predicted_test_pr2 <- predict.lm(modelo_propio_2, DT_test)

#Calculo los RMSE en train
RMSE_train_ini <- rmse(actual_train, predicted_train_ini)
RMSE_train_cat <- rmse(actual_train, predicted_train_cat)
RMSE_train_pr1 <- rmse(actual_train, predicted_train_pr1)
RMSE_train_pr2 <- rmse(actual_train, predicted_train_pr2)

#Calculo los RMSE en test
RMSE_test_ini <- rmse(actual_test, predicted_test_ini)
RMSE_test_cat <- rmse(actual_test, predicted_test_cat)
RMSE_test_pr1 <- rmse(actual_test, predicted_test_pr1)
RMSE_test_pr2 <- rmse(actual_test, predicted_train_pr2)

#Calculo los MAE en train
MAE_train_ini <- mae(actual_train, predicted_train_ini)
MAE_train_cat <- mae(actual_train, predicted_train_cat)
MAE_train_pr1 <- mae(actual_train, predicted_train_pr1)
MAE_train_pr2 <- mae(actual_train, predicted_train_pr2)

#Calculo los MAE en test
MAE_test_ini <- mae(actual_test, predicted_test_ini)
MAE_test_cat <- mae(actual_test, predicted_test_cat)
MAE_test_pr1 <- mae(actual_test, predicted_test_pr1)
MAE_test_pr2 <- mae(actual_test, predicted_train_pr2)

df <- data.frame (modelo= c("inicial", "categorias", "propio 1", "propio 2"),
                  rmse_train  = c( RMSE_train_ini, RMSE_train_cat, RMSE_train_pr1, RMSE_train_pr2),
                  rmse_test = c(RMSE_test_ini, RMSE_test_cat, RMSE_test_pr1, RMSE_test_pr2),                              mae_train=c(MAE_train_ini, MAE_train_cat, MAE_train_pr1, MAE_train_pr2),
                  mae_test=c(MAE_test_ini, MAE_test_cat, MAE_test_pr1, MAE_test_pr2)
                  )


df
```

El mejor modelo para predecir el peso es el de categorías, porque es el que tiene menores errores en el set de testeo. El modelo propio 2 es el que mejor ajusta a los datos de entrenamiento (fue construido para esto), pero evidentemente sufre de sobreajuste porque sus errores en el set de validación son muy altos.

### 5) Diagnóstico del modelo ###Analizar en profundidad el cumplimiento de los supuestos del modelo lineal para el modelo inicial.

Comenzamos por graficar la distribución de todos los residuos.

```{r}
#calculo los errores
pesos <- data.frame( actual=actual_train, predicted=predicted_train_ini, errores=predicted_train_ini-actual_train )

#Los reordeno segun el peso real
pesos <- pesos[order(pesos$actual),]


#Creo una funcion densidad
den <- density(pesos$errores)

#Grafico la densidad
ggplot(data.frame(x = den$x, y = den$y)) + 
  aes(x = x, y = y) + geom_line() + geom_vline(aes(xintercept=mean(0)),
            color="blue", linetype="dashed", size=1) + scale_y_continuous(expand = c(0, 0), limits = c(0, 0.05))


```

Se observa que la distribución es altamaente asimétrica, con un pico de densidad corrido hacia los valores positivos de residuos. El modelo sobreestima el peso en más cantidad de registros, y subestima con mayores magnitudes para compensar y promediar error cero.

Hacemos a continuación los gráficos de las distribuciones de error para cada cuartil de peso real:

```{r}
#Primer cuartil
a <- pesos$errores[1:1756]
den1 <- density(a)
#Grafico la densidad
p1 <- ggplot(data.frame(x = den1$x, y = den1$y)) + 
        aes(x = x, y = y) + geom_line() + geom_vline(aes(xintercept=0),
            color="blue", linetype="dashed", size=1) + scale_y_continuous(expand = c(0, 0), limits = c(0, 0.075)) +                                geom_vline(aes(xintercept=mean(a)), color="red", linetype="dashed", size=1)


#Segundo cuartil
b <- pesos$errores[1750:3512]
den2 <- density(b)
#Grafico la densidad
p2 <- ggplot(data.frame(x = den2$x, y = den2$y)) + 
        aes(x = x, y = y) + geom_line() + geom_vline(aes(xintercept=0),
            color="blue", linetype="dashed", size=1) + scale_y_continuous(expand = c(0, 0), limits = c(0, 0.075)) +                                geom_vline(aes(xintercept=mean(b)), color="red", linetype="dashed", size=1)

#Tercer cuartil
c <- pesos$errores[3500:5268]
den3 <- density(c)
#Grafico la densidad
p3 <- ggplot(data.frame(x = den3$x, y = den3$y)) + 
        aes(x = x, y = y) + geom_line() + geom_vline(aes(xintercept=0),
            color="blue", linetype="dashed", size=1) + scale_y_continuous(expand = c(0, 0), limits = c(0, 0.075)) +                                geom_vline(aes(xintercept=mean(c)), color="red", linetype="dashed", size=1)

#Cuarto cuartil
d <- pesos$errores[5250:7024]
den4 <- density(d)
#Grafico la densidad
p4 <- ggplot(data.frame(x = den4$x, y = den4$y)) + 
        aes(x = x, y = y) + geom_line() + geom_vline(aes(xintercept=0),
            color="blue", linetype="dashed", size=1) + scale_y_continuous(expand = c(0, 0), limits = c(0, 0.075)) +                                geom_vline(aes(xintercept=mean(d)), color="red", linetype="dashed", size=1)

#Uno los gráficos
figure <- ggarrange(p1, p2,p3,p4,
                    ncol = 2, nrow = 2,
                    labels = c("Primer cuartil", "Segundo cuartil", "Tercer cuartil", "Cuarto cuartil"),
                    common.legend = TRUE, legend = "bottom")
figure
```

La linea vertical roja marca el valor medio de los errores en cada cuartil. Se nota que el modelo sobrestima en promedio para el primer y segundo cuartil, y subestima en promedio en el tercero y cuarto. La forma de las distribuciones también cambia respecto al peso, por lo que no se cumple la homoelasticidad.

Hacemos gráficos de Residuos vs valores predichos, Normal QQ plot, scale location y Residual vs leverage.

```{r}
plot(modelo_inicial)
```

En Normal QQ plot, vemos que los residuos se desvian mucho de la distribución normal para el extremo derecho.

Concluimos entonces que el modelo inicial no cumple con los supuestos del modelo lineal.

### 6) Modelo Robusto

### Leer el archivo "encuesta_salud_modelo6.csv". Este último consiste en el dataset original de train con la incorporación de algunas observaciones adicionales que pueden incluir valores atípicos. En particular, observar la relación entre peso y altura ¿Qué ocurre con estos nuevos datos?

Comenzamos graficando la relación peso y altura en el dataset original de entrenamiento y el nuevo dataset:

```{r}
#El nuevo dataset es DT_6

#Graficamos peso en función de la altura:
p2 <- ggplot(DT_6,  aes(altura, peso)) + 
  geom_point(aes(y = peso), size=1.8, alpha=0.1)

p1 <- ggplot(DT,  aes(altura, peso)) + 
  geom_point(aes(y = peso), size=1.8, alpha=0.1) + ylim(20,200)
  
figure <- ggarrange(p1, p2,
                    ncol = 2, nrow = 1,
                    labels = c("Dataset train", "Dataset nuevo"),
                    common.legend = TRUE, legend = "bottom")
figure


```

Observo que estos nuevos datos se encuentran muy por arriba de los demás en términos de peso en función de la altura, son valores atípicos.

### Entrenar el modelo inicial con estos nuevos datos y comentar qué se observa en los coeficientes estimados y las métricas de evaluación (R cuadrado ajustado, RMSE y MAE) respecto al modelo entrenado con el set de entrenamiento original.

Explicito los detalles del modelo inicial sobre los datos iniciales y sobre los nuevos:

```{r}

#Ajustamos el modelo inicial al dataset train
modelo_inicial <- lm(peso ~ altura+edad+genero+a_fisica+c_alcohol, data = DT)

#Resumen del modelo
summary(modelo_inicial)


```

```{r}

#Ajustamos el modelo inicial al nuevo dataset
modelo_inicial_6 <- lm(peso ~ altura+edad+genero+a_fisica+c_alcohol, data = DT_6)

#Resumen del modelo
summary(modelo_inicial_6)


```

Observo que los coeficientes que son significativos (los correspondientes a intercept, altura, edad y genero masculino), cambian drásticamente por la adición de estos datos atípicos. El que menos cambia, en porcentaje, es el de edad, de 1.406727 a 1.86859. Los coeficientes correspondientes a a_fisica y c_alcohol también sufren cambios, pero se mantienen pequeños y no son significativos en ningún modelo.

El R cuadrado ajustado disminuye a menos de un tercio, de 0.3539 a 0.1095, por los datos agregados.

Calculo luego el RMSE Y MAE:

```{r}

#obtengo los valores reales
actual_6 <- DT_6$peso


#Obtengo los valores predichos
predicted_6_ini <- predict.lm(modelo_inicial_6, DT_6)


#Calculo los RMSE en los datos nuevos
RMSE_6_ini <- rmse(actual_6, predicted_6_ini)


#Calculo los MAE en los datos nuevos
MAE_6_ini <- mae(actual_6, predicted_6_ini)



df <- data.frame (datos= c("originales", "nuevos"),
                  rmse  = c( RMSE_train_ini, RMSE_6_ini),
                  mae=c(MAE_train_ini, MAE_6_ini))


df
```

El MAE y RMSE aumentan. Esto ocurriría siempre que se agregan nuevos nuevos datos y se mantiene la misma especificación de modelo. Sin embargo, en este caso, el aumento de los errores es desproporcionado (+58.8% del RMSE y +38.4% del MAE) respecto al aumento de cantidad de registros del conjunto, que es solo del 1.49%. Esta es una consecuencia de que los nuevos datos son muy atípicos en comparación con la distribución de los originales.

### Entrenar un modelo robusto con la misma especificación que el modelo inicial sobre los nuevos datos. 

Ajustamos un modelo robusto usando estimación M.
```{r}
#Ajustamos el modelo robusto al nuevo dataset
modelo_r_6 <- rlm(peso ~ altura+edad+genero+a_fisica+c_alcohol, data = DT_6)

#Resumen del modelo
summary(modelo_r_6)
```
### Comparar los coeficientes y su performance (RMSE y MAE) respecto al modelo inicial no robusto entrenado en este punto. ¿Qué puede concluir al respecto?

Observo que los coeficientes del modelo robusto intercept, altura, edad y genero masculino son más similares a los del modelo inicial sin los datos nuevos que los del modelo inicial con los datos nuevos.

Calculamos el MAE Y RMSE del modelo robusto:
```{r}
#Calculamos los errores
predicted_rob <- predict(modelo_r_6)

#Calculo el RMSE
RMSE_r_6 <- rmse(actual_6, predicted_rob)

#Calculo el MAE
MAE_r_6 <- mae(actual_6, predicted_rob)



df <- data.frame (datos= c("modelo inicial", "robusto"),
                  rmse  = c( RMSE_6_ini, RMSE_r_6),
                  mae=c(MAE_6_ini, MAE_r_6))

df
```
El RMSE es menor para el modelo inicial, el MAE es menor para el modelo robusto. 

Estos resultados son consistentes con nuestro entendimiento de los modelos:

El modelo clásico se obtiene minimizando la suma de los errores cuadráticos, por lo que obtiene el menor RMSE posible, dados los constraints de su formula.

Elevar los errores al cuadrado antes de sumarlos aumenta desproporcionadamente la magnitud de los errores grandes, por lo que el modelo clásico le da alta importancia a los valores atípicos. Esto se refleja en valores muy distintos de los coeficientes del modelo inicial al agregar unos pocos datos atípicos.

El modelo robusto busca limitar el impacto de los valores atípicos, asignando iterativamente un peso cada residuo al cuadrado, en la suma a minimizar. Este peso es menor mientras más atípico es el valor, algo que se calcula en iteraciones anteriores. 

Esto resulta (en comparación con el modelo clásico) en  coeficientes más similares a los de el modelo inicial sin los datos atípicos. Esta nueva forma de asignar pesos tiende a disminuir tambien en promedio los modulos de los errores, por lo que disminuye levemente el MAE.
